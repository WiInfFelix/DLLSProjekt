{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "DLLS Keras with CRF",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm",
      "mount_file_id": "1qZhJrUoBf5kfmA3xysnFTbXqhv775Oyh",
      "authorship_tag": "ABX9TyPMpOH8migkvgYwCOuSSFnE",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/WiInfFelix/DLLSProjekt/blob/master/DLLS_Keras_v2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D5ke3t57oG57",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "from tensorflow import keras\n",
        "import tensorflow as tf\n",
        "import tensorflow_datasets as tfds\n",
        "tfds.disable_progress_bar()\n",
        "\n",
        "from tqdm import tqdm\n",
        "from spacy.lang.en import English\n",
        "from pprint import pprint\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import pickle\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn import preprocessing\n",
        "from keras.callbacks import EarlyStopping\n",
        "\n",
        "\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, LSTM, InputLayer, Bidirectional, TimeDistributed, Embedding, Activation\n",
        "from keras.models import Sequential, load_model\n",
        "from keras.layers import Dense, Dropout\n",
        "from keras.layers import Embedding\n",
        "from keras.layers import LSTM\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "import spacy\n",
        "import re\n",
        "import time"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AeYpqO2ZoPau",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "pickle_list = \"/content/drive/My Drive/Master Wirtschaftsinformatik/3. Semester /DLLS/DLLSProjekt/list.p\"\n",
        "pickle_texts = \"/content/drive/My Drive/Master Wirtschaftsinformatik/3. Semester /DLLS/DLLSProjekt/texts.p\"\n",
        "dev_pickle = \"/content/drive/My Drive/Master Wirtschaftsinformatik/3. Semester /DLLS/DLLSProjekt/dev_articles_pickle\"\n",
        "dev_articles = \"/content/drive/My Drive/Master Wirtschaftsinformatik/3. Semester /DLLS/DLLSProjekt/datasets/dev-articles\"\n",
        "train_articles = \"\"\n",
        "\n",
        "dataset_folder = \"/content/drive/My Drive/Master Wirtschaftsinformatik/3. Semester /DLLS/DLLSProjekt/datasets\"\n",
        "train_texts = \"/content/drive/My Drive/Master Wirtschaftsinformatik/3. Semester /DLLS/DLLSProjekt/datasets/train-articles\"\n",
        "train_labels = \"/content/drive/My Drive/Master Wirtschaftsinformatik/3. Semester /DLLS/DLLSProjekt/datasets/train-labels-task1-span-identification\"\n",
        "model_save_file = \"/content/drive/My Drive/Master Wirtschaftsinformatik/3. Semester /DLLS/DLLSProjekt/keras_model2.h5\"\n",
        "\n",
        "\n",
        "left_context = 4\n",
        "right_context = 0"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D3V0FolePOrd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Article:\n",
        "    def __init__(self, article_id, tokens, words):\n",
        "        self.tokens = tokens\n",
        "        self.article_id = article_id\n",
        "        self.words = words\n",
        "\n",
        "class Word:\n",
        "  def __init__(self, text, idx, prop_class):\n",
        "    self.text = text\n",
        "    self.idx = idx\n",
        "    self.prop_class = prop_class"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zlm6003TqEej",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_data(train_test_size):\n",
        "    input_list = pickle.load(open(pickle_list, \"rb\"))\n",
        "    ## Take a subset\n",
        "    corpus_words = [x[0] for x in input_list]\n",
        "    corpus_tags = [x[1] for x in input_list]\n",
        "\n",
        "    word_encoder = LabelEncoder()\n",
        "    label_encoder = LabelEncoder()\n",
        "\n",
        "    corpus_words_num = word_encoder.fit_transform(corpus_words)\n",
        "    corpus_tags_num = label_encoder.fit_transform(corpus_tags)\n",
        "\n",
        "    input_dim = len(word_encoder.classes_)\n",
        "    output_dim = len(label_encoder.classes_)\n",
        "\n",
        "    return word_encoder, label_encoder, corpus_words_num, corpus_tags_num, input_dim, output_dim\n",
        "\n",
        "\n",
        "def prepare_data(left_context_len, right_context_len, train_test_size):\n",
        "    word_encoder, label_encoder, x_data, y_data, input_dim, output_dim, = get_data(train_test_size)\n",
        "\n",
        "    train_data = [(x_data[i - left_context_len:i + right_context_len + 1], y_data[i]) for i in\n",
        "                  range(left_context_len, len(x_data) - right_context_len)]\n",
        "    x_train = np.array([pair[0] for pair in train_data])\n",
        "    y_train = np.array([pair[1] for pair in train_data])\n",
        "\n",
        "    return input_dim, output_dim, x_train, y_train, word_encoder, label_encoder\n",
        "\n",
        "\n",
        "def get_dev_data():\n",
        "  nlp = spacy.load(\"en_core_web_sm\")\n",
        "\n",
        "  id_getter = re.compile(r'\\d+')\n",
        "\n",
        "  articles_dict = {}\n",
        "  word_list = []\n",
        "\n",
        "  num_file = len(os.listdir(dev_articles))\n",
        "  print(f'{num_file} files have been found!')\n",
        "\n",
        "  for entry in tqdm(os.scandir(dev_articles), total=75):\n",
        "    with open(entry, encoding=\"utf-8\") as file:\n",
        "      text = file.read()\n",
        "      tokens = nlp(text)\n",
        "      np_tokens = np.array(tokens)\n",
        "      #print(type(np_tokens))\n",
        "      for tok in tokens:\n",
        "        word_list.append(tok.text)\n",
        "      #time.sleep(1)\n",
        "      article_id = id_getter.search(entry.name).group(0)\n",
        "      #article = Article(article_id, tokens)\n",
        "      articles_dict[article_id] = np_tokens\n",
        "\n",
        "  print(f'Finished scanning articles. {len(articles_dict)} have been read in...')\n",
        "\n",
        "  print(f'Finished reading in!')\n",
        "\n",
        "  return articles_dict, word_list\n",
        "\n",
        "\n",
        "\n",
        "def main():\n",
        "    # model size parameters\n",
        "    left_context_len = 4\n",
        "    right_context_len = 0\n",
        "\n",
        "    # set this higher to get a better model\n",
        "    train_test_size = 200000\n",
        "    embedding_dim = 1000\n",
        "\n",
        "    ## Hyperparemeters: experiment with these, too\n",
        "    learning_rate = 0.01\n",
        "    epochs =  10\n",
        "\n",
        "    seq_len = left_context_len + 1 + right_context_len\n",
        "    input_dim, output_dim, x_data, y_data, word_encoder, label_encoder = prepare_data(left_context_len, right_context_len, train_test_size)\n",
        "    x_train, x_test, y_train, y_test = train_test_split(x_data, y_data)\n",
        "    #x, y, optimizer, loss, pred_argmax = build_graph(seq_len, input_dim, output_dim, embedding_dim, learning_rate)\n",
        "\n",
        "    config = tf.ConfigProto()\n",
        "    config.gpu_options.allow_growth = True\n",
        "\n",
        "    config = tf.ConfigProto( device_count = {'GPU': 1 , 'CPU': 4} ) \n",
        "    sess = tf.Session(config=config) \n",
        "    keras.backend.set_session(sess)\n",
        "\n",
        "    es = EarlyStopping(monitor='val_loss', mode='min', verbose=1)\n",
        "  \n",
        "    model = Sequential()\n",
        "    model.add(Embedding(input_dim, output_dim=int(input_dim**0.5)))\n",
        "    model.add(LSTM(1024))\n",
        "    model.add(Dropout(0.1))\n",
        "    model.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "    model.compile(loss='binary_crossentropy',\n",
        "              optimizer='adam',\n",
        "              metrics=['binary_accuracy'])\n",
        "              #Ã¤\n",
        "    \n",
        "    model = load_model(model_save_file)\n",
        "\n",
        "    #model.fit(x_train, y_train, batch_size=32, epochs=20, validation_split=0.2, callbacks = [es])\n",
        "    #model.save(model_save_file)  # creates a HDF5 file 'my_model.h5'\n",
        "    #score = model.evaluate(x_test, y_test, batch_size=32)\n",
        "    #print(score)\n",
        "\n",
        "    dev_data, dev_list = get_dev_data()\n",
        "    #print(dev_data)\n",
        "    encoded_dev = {}\n",
        "    dev_list_dec = dev_list\n",
        "\n",
        "    '''\n",
        "    for entry in dev_data:\n",
        "      encoded_dev[entry.key()] = word_encoder.fit_transform(entry)\n",
        "\n",
        "    for entry in encoded_dev:\n",
        "      model.predict(entry.value())\n",
        "    '''\n",
        "\n",
        "    dev_list = word_encoder.fit_transform(dev_list)\n",
        "    #dev_list = einteilen in ein Aufteilung wie train array\n",
        "\n",
        "    dev_list = np.array(dev_list)\n",
        "\n",
        "    res = model.predict(dev_list)\n",
        "\n",
        "    first_res = ([\"o\" if x >= 0.5 else \"PROP\" for x in res[:400]])\n",
        "\n",
        "    print(\"{:15}||{}\".format(\"Word\", \"Prediction\"))\n",
        "    print(30 * \"=\")\n",
        "    for w, pred in zip(dev_list_dec[:400], first_res):\n",
        "        print(\"{:15}: {:5}\".format(w, pred))\n",
        "\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    main()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JPNQw2SzepI8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "Word           ||Prediction\n",
        "==============================\n",
        "From           : o    \n",
        "Bad            : o    \n",
        "To             : PROP \n",
        "Worse          : o    \n",
        "?              : o    \n",
        "\n",
        "              : o    \n",
        "Tillerson      : o    \n",
        "Out            : o    \n",
        "â              : o    \n",
        "CIA            : o    \n",
        "Director       : o    \n",
        "Pompeo         : o    \n",
        "In             : o    \n",
        "At             : o    \n",
        "State          : PROP \n",
        "Dept           : o    \n",
        "â              : o    \n",
        "Gina           : o    \n",
        "Haspel         : o    \n",
        "As             : o    \n",
        "Head           : o    \n",
        "Of             : o    \n",
        "CIA            : o    \n",
        "\n",
        "\n",
        "             : o    \n",
        "From           : o    \n",
        "Bad            : o    \n",
        "To             : PROP \n",
        "Worse          : o    \n",
        "?              : o    \n",
        "\n",
        "              : o    \n",
        "Tillerson      : o    \n",
        "Out            : o    \n",
        "â              : o    \n",
        "CIA            : o    \n",
        "Director       : o    \n",
        "Pompeo         : o    \n",
        "In             : o    \n",
        "At             : o    \n",
        "State          : PROP \n",
        "Dept           : o    \n",
        "â              : o    \n",
        "Gina           : o    \n",
        "Haspel         : o    \n",
        "As             : o    \n",
        "Head           : o    \n",
        "Of             : o    \n",
        "CIA            : o    \n",
        "\n",
        "              : o    \n",
        "Please         : o    \n",
        "help           : PROP \n",
        "support        : o    \n",
        "us             : o    \n",
        "with           : o    \n",
        "cryptocurrency : o    \n",
        "donations      : o    \n",
        ".              : o    \n",
        "\n",
        "              : o    \n",
        "Thank          : PROP \n",
        "you            : o    \n",
        "!              : o    \n",
        "\n",
        "              : o    \n",
        "Keeping        : o    \n",
        "things         : o    \n",
        "moving         : o    \n",
        ",              : o    \n",
        "and            : o    \n",
        "I              : o    \n",
        "think          : o    \n",
        "a              : o    \n",
        "lot            : o    \n",
        "of             : o    \n",
        "us             : o    \n",
        "can            : o    \n",
        "just           : PROP \n",
        "shout          : o    \n",
        "out            : o    \n",
        ",              : o    \n",
        "â              : o    \n",
        "What           : o    \n",
        "are            : o    \n",
        "you            : o    \n",
        "thinking       : o    \n",
        "?              : o    \n",
        "â              : o    \n",
        "as             : o    \n",
        "President      : o    \n",
        "Donald         : PROP \n",
        "Trump          : o    \n",
        "brings         : PROP \n",
        "CIA            : o    \n",
        "Director       : o    \n",
        "Mike           : o    \n",
        "Pompeo         : o    \n",
        ",              : o    \n",
        "a              : o    \n",
        "man            : o    \n",
        "that           : PROP \n",
        "blasted        : o    \n",
        "the            : o    \n",
        "likes          : o    \n",
        "of             : o    \n",
        "Edward         : o    \n",
        "Snowden        : o    \n",
        "for            : o    \n",
        "revealing      : o    \n",
        "the            : o    \n",
        "crimes         : o    \n",
        "of             : o    \n",
        "our            : o    \n",
        "government     : o    \n",
        ",              : o    \n",
        "to             : o    \n",
        "the            : o    \n",
        "State          : PROP \n",
        "Department     : o    \n",
        "and            : o    \n",
        "installs       : o    \n",
        "Gina           : o    \n",
        "Haspel         : o    \n",
        "in             : o    \n",
        "the            : o    \n",
        "position       : o    \n",
        "of             : o    \n",
        "head           : PROP \n",
        "of             : o    \n",
        "the            : o    \n",
        "Central        : PROP \n",
        "Intelligence   : o    \n",
        "Agency         : o    \n",
        ".              : o    \n",
        "\n",
        "              : o    \n",
        "Trump          : o    \n",
        "tweeted        : o    \n",
        "out            : o    \n",
        "the            : o    \n",
        "news           : o    \n",
        "on             : o    \n",
        "Tuesday        : PROP \n",
        ".              : o    \n",
        "\n",
        "              : o    \n",
        "â              : o    \n",
        "Mike           : o    \n",
        "Pompeo         : o    \n",
        ",              : o    \n",
        "Director       : o    \n",
        "of             : o    \n",
        "the            : o    \n",
        "CIA            : o    \n",
        ",              : o    \n",
        "will           : o    \n",
        "become         : PROP \n",
        "our            : o    \n",
        "new            : o    \n",
        "Secretary      : PROP \n",
        "of             : o    \n",
        "State          : PROP \n",
        ".              : o    \n",
        "\n",
        "              : o    \n",
        "He             : o    \n",
        "will           : o    \n",
        "do             : PROP \n",
        "a              : o    \n",
        "fantastic      : o    \n",
        "job            : o    \n",
        "!              : o    \n",
        "\n",
        "              : o    \n",
        "Thank          : PROP \n",
        "you            : o    \n",
        "to             : o    \n",
        "Rex            : PROP \n",
        "Tillerson      : o    \n",
        "for            : o    \n",
        "his            : o    \n",
        "service        : o    \n",
        "!              : o    \n",
        "\n",
        "              : o    \n",
        "Gina           : o    \n",
        "Haspel         : o    \n",
        "will           : o    \n",
        "become         : PROP \n",
        "the            : o    \n",
        "new            : o    \n",
        "Director       : o    \n",
        "of             : o    \n",
        "the            : o    \n",
        "CIA            : o    \n",
        ",              : o    \n",
        "and            : o    \n",
        "the            : o    \n",
        "first          : o    \n",
        "woman          : o    \n",
        "so             : PROP \n",
        "chosen         : PROP \n",
        ".              : o    \n",
        "\n",
        "              : o    \n",
        "Congratulations: PROP \n",
        "to             : o    \n",
        "all            : o    \n",
        "!              : o    \n",
        "â              : o    \n",
        "he             : o    \n",
        "tweeted        : o    \n",
        ".              : o    \n",
        "\n",
        "              : o    \n",
        "Mike           : o    \n",
        "Pompeo         : o    \n",
        ",              : o    \n",
        "Director       : o    \n",
        "of             : o    \n",
        "the            : o    \n",
        "CIA            : o    \n",
        ",              : o    \n",
        "will           : o    \n",
        "become         : PROP \n",
        "our            : o    \n",
        "new            : o    \n",
        "Secretary      : PROP \n",
        "of             : o    \n",
        "State          : PROP \n",
        ".              : o    \n",
        "\n",
        "              : o    \n",
        "He             : o    \n",
        "will           : o    \n",
        "do             : PROP \n",
        "a              : o    \n",
        "fantastic      : o    \n",
        "job            : o    \n",
        "!              : o    \n",
        "\n",
        "              : o    \n",
        "Thank          : PROP \n",
        "you            : o    \n",
        "to             : o    \n",
        "Rex            : PROP \n",
        "Tillerson      : o    \n",
        "for            : o    \n",
        "his            : o    \n",
        "service        : o    \n",
        "!              : o    \n",
        "\n",
        "              : o    \n",
        "Gina           : o    \n",
        "Haspel         : o    \n",
        "will           : o    \n",
        "become         : PROP \n",
        "the            : o    \n",
        "new            : o    \n",
        "Director       : o    \n",
        "of             : o    \n",
        "the            : o    \n",
        "CIA            : o    \n",
        ",              : o    \n",
        "and            : o    \n",
        "the            : o    \n",
        "first          : o    \n",
        "woman          : o    \n",
        "so             : PROP \n",
        "chosen         : PROP \n",
        ".              : o    \n",
        "\n",
        "              : o    \n",
        "Congratulations: PROP \n",
        "to             : o    \n",
        "all            : o    \n",
        "!              : o    \n",
        "\n",
        "              : o    \n",
        "â              : o    \n",
        "Donald         : PROP \n",
        "J.             : PROP \n",
        "Trump          : o    \n",
        "(              : o    \n",
        "@realDonaldTrump: o    \n",
        ")              : PROP \n",
        "March          : PROP \n",
        "13             : o    \n",
        ",              : o    \n",
        "2018           : o    \n",
        "\n",
        "              : o    \n",
        "The            : PROP \n",
        "Washington     : o    \n",
        "Post           : o    \n",
        "first          : o    \n",
        "reported       : o    \n",
        "on             : o    \n",
        "the            : o    \n",
        "story          : o    \n",
        "prior          : o    \n",
        "to             : o    \n",
        "Trump          : o    \n",
        "âs             : o    \n",
        "tweet          : o    \n",
        ".              : o    \n",
        "\n",
        "              : o    \n",
        "Trump          : o    \n",
        "and            : o    \n",
        "Tillerson      : o    \n",
        "have           : o    \n",
        "had            : PROP \n",
        "a              : o    \n",
        "fraught        : o    \n",
        "relationship   : o    \n",
        "for            : o    \n",
        "many           : PROP \n",
        "months         : o    \n",
        ".              : o    \n",
        "\n",
        "              : o    \n",
        "Trump          : o    \n",
        "told           : o    \n",
        "reporters      : o    \n",
        "Tuesday        : PROP \n",
        "that           : PROP \n",
        "he             : o    \n",
        "ultimately     : o    \n",
        "decided        : o    \n",
        "to             : o    \n",
        "fire           : o    \n",
        "the            : o    \n",
        "secretary      : o    \n",
        "because        : o    \n",
        "they           : o    \n",
        "disagreed      : o    \n",
        "over           : o    \n",
        "strategy       : o    \n",
        "in             : o    \n",
        "key            : o    \n",
        "areas          : o    \n",
        "of             : o    \n",
        "foreign        : PROP \n",
        "policy         : PROP \n",
        ",              : o    \n",
        "such           : o    \n",
        "as             : o    \n",
        "the            : o    \n",
        "2015           : o    \n",
        "Iran           : o    \n",
        "nuclear        : o    \n",
        "deal           : PROP \n",
        ",              : o    \n",
        "the            : o    \n",
        "approach       : o    \n",
        "to             : o    \n",
        "North          : o    \n",
        "Korea          : o    \n",
        "and            : o    \n",
        "the            : o    \n",
        "overall        : o    \n",
        "tone           : o    \n",
        "of             : o    \n",
        "U.S.           : o    \n",
        "diplomacy      : o    \n",
        ".              : o    \n",
        "\n",
        "              : o    \n",
        "Tillerson      : o    \n",
        "said           : o    \n",
        "he             : o    \n",
        "received       : o    \n",
        "a              : o    \n",
        "call           : o    \n",
        "from           : o    \n",
        "Trump          : o    \n",
        "around         : o    \n",
        "noon           : o    \n",
        "Tuesday        : PROP \n",
        ",              : o    \n",
        "more           : o    \n",
        "than           : o    \n",
        "three          : o    \n",
        "hours          : o    \n",
        "after          : PROP \n",
        "his            : o    \n",
        "firing         : o    \n",
        "was            : o    \n",
        "first          : o    \n",
        "reported       : o    \n",
        "by             : o    \n",
        "The            : PROP \n",
        "Washington     : o    \n",
        "Post           : o    \n",
        "and            : o    \n",
        "announced      : o    \n",
        "minutes        : PROP \n",
        "later          : PROP \n",
        "in             : o    \n",
        "a              : o    \n",
        "tweet          : o    \n",
        "from           : o    \n",
        "the            : o    \n",
        "president      : o    \n",
        ".              : o    \n",
        "\n",
        "              : o    \n",
        "His            : o    \n",
        "voice          : o    \n",
        "quivering      : o    \n",
        ",              : o    \n",
        "Tillerson      : o    \n",
        "thanked        : o    \n",
        "career         : o    \n",
        "diplomats      : o    \n",
        "for            : o    \n",
        "their          : PROP \n",
        "â              : o    \n",
        "honesty        : o    \n",
        "and            : o    "
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}